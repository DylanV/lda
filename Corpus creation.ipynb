{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def read_ratings(file_path, sep='::'):\n",
    "    ratings_file = os.path.abspath(file_path)\n",
    "    column_names = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "    ratings = pd.read_csv(ratings_file, names=column_names, sep=sep, engine='python')\n",
    "    ratings = ratings.drop('timestamp', axis=1)\n",
    "    ratings[['userId', 'movieId']] = ratings[['userId', 'movieId']].astype('int32')\n",
    "    ratings[['rating']] = ratings[['rating']].astype('int8')\n",
    "    ratings = ratings.pivot('userId', 'movieId', 'rating').fillna(value=0)\n",
    "    return ratings\n",
    "\n",
    "def split_train_test(ratings, test_ratio=0.2):\n",
    "    test = pd.DataFrame(np.zeros(ratings.shape), index=ratings.index, columns=ratings.columns)\n",
    "    train = pd.DataFrame(np.zeros(ratings.shape), index=ratings.index, columns=ratings.columns)\n",
    "\n",
    "    for user in xrange(ratings.shape[0]):\n",
    "        user_ratings_indexes = ratings.iloc[user, :].nonzero()[0]\n",
    "        train_indexes, test_indexes = train_test_split(user_ratings_indexes, test_size=test_ratio)\n",
    "        train.iloc[user, train_indexes] = ratings.iloc[user, train_indexes]\n",
    "        test.iloc[user, test_indexes] = ratings.iloc[user, test_indexes]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def get_sim(userId, movieId, gamma, pzw, movies, topics):\n",
    "    movie1 = pzw[movies.get_loc(movieId)]\n",
    "    user1 = gamma[userId]\n",
    "\n",
    "    top = user1.multiply(movie1)\n",
    "    user_tot = 0\n",
    "    movie_tot = 0\n",
    "    for i in xrange(topics):\n",
    "        user_tot += user1[i] * user1[i]\n",
    "        movie_tot += movie1[i] * movie1[i]\n",
    "    user_tot = np.sqrt(user_tot)\n",
    "    movie_tot = np.sqrt(movie_tot)\n",
    "    sim = top.sum() / (user_tot * movie_tot)\n",
    "    return sim\n",
    "\n",
    "def get_similiarity_matrix(ratings):\n",
    "    user_similarity = ratings.dot(ratings.transpose())\n",
    "    normalisation_terms = pd.DataFrame(np.diagonal(user_similarity.values), index=ratings.index).apply(np.sqrt)\n",
    "    normalisation_terms = normalisation_terms.dot(normalisation_terms.transpose())\n",
    "    user_similarity = user_similarity.div(normalisation_terms)\n",
    "    return user_similarity\n",
    "\n",
    "def get_rmse(predicted, actual):\n",
    "    return np.sqrt(mean_squared_error(actual.values[actual.values.nonzero()].flatten(),\n",
    "                                      predicted.values[actual.values.nonzero()].flatten()))\n",
    "\n",
    "def adjust_user_similarity_knn(user_similarity, k):\n",
    "        adjusted_similarity = pd.DataFrame(np.zeros(user_similarity.shape),\n",
    "                                           index=user_similarity.index, columns=user_similarity.columns)\n",
    "\n",
    "        for user in user_similarity.iterrows():\n",
    "            top_k_indexes = user[1].sort_values(ascending=False).iloc[0:k+1].index.values\n",
    "            adjusted_similarity.loc[user[0], top_k_indexes] = user_similarity.loc[user[0], top_k_indexes]\n",
    "\n",
    "        return adjusted_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), \"datasets_rating\", \"ml1m\", \"ratings.dat\")\n",
    "full = read_ratings(path)\n",
    "\n",
    "users= full.index\n",
    "movies = pd.Index(full.columns.unique())\n",
    "\n",
    "ratings, test = split_train_test(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = ratings.replace(0, np.nan)\n",
    "user_means = pd.DataFrame(ratings.mean(axis=1), index=ratings.index, columns=['mean']).fillna(value=0)\n",
    "item_means = pd.DataFrame(ratings.mean(axis=0), index=ratings.columns, columns=['mean']).fillna(value=0)\n",
    "# user_offsets = ratings.subtract(item_means['mean'], 1).abs().mean(axis=1)\n",
    "user_offsets = ratings.subtract(user_means['mean'], 0).abs().mean(axis=1)\n",
    "new = ratings.subtract(user_means['mean'], 0).divide(user_offsets, 0).transpose().unstack().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fo = open(\"rating.dat\", \"w\")\n",
    "\n",
    "line = str(len(movies)) + \" \"\n",
    "for movie in movies:\n",
    "    line += str(movies.get_loc(movie)) + \":1 \"\n",
    "line += \"\\n\"\n",
    "fo.write(line)\n",
    "\n",
    "neg_docs = \"\"\n",
    "\n",
    "for user in users:\n",
    "    pos_doc = \"\"\n",
    "    neg_doc = \"\"\n",
    "    \n",
    "    count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    for item in new[user].iteritems():\n",
    "        rating = item[1]\n",
    "        if rating < 0:\n",
    "            score = 0\n",
    "            neg_count += 1\n",
    "            if rating > -1:\n",
    "                score = 1\n",
    "            else:\n",
    "                score = 2\n",
    "                \n",
    "            neg_doc += str(movies.get_loc(item[0])) + \":\" + str(score) + \" \"\n",
    "                \n",
    "        elif rating >= 0:\n",
    "            count += 1\n",
    "            score = 0\n",
    "            if rating < 1:\n",
    "                score = 1\n",
    "            else:\n",
    "                score = 2\n",
    "            \n",
    "            pos_doc += str(movies.get_loc(item[0])) + \":\" + str(score) + \" \"\n",
    "            \n",
    "    line = str(count) + \" \" + pos_doc + \"\\n\"\n",
    "    neg_docs += str(neg_count) + \" \" + neg_doc + \"\\n\"\n",
    "    fo.write(line)\n",
    "    \n",
    "fo.write(neg_docs)\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = 100\n",
    "# load gamma\n",
    "path = os.path.join(os.getcwd(), \"cpp\", \"params\", \"ratings\", str(topics), \"gamma.dat\")\n",
    "gamma = pd.read_table(path, sep=\" \", skiprows=1, header = None).transpose()\n",
    "\n",
    "#load beta and get p(z|w)\n",
    "path = os.path.join(os.getcwd(), \"cpp\", \"params\", \"ratings\", str(topics), \"beta.dat\")\n",
    "beta = pd.read_table(path, sep=\" \", skiprows=1, header = None)\n",
    "pw = beta.sum(0)\n",
    "pz = beta.sum(1)\n",
    "pw = pw / pw.sum()\n",
    "pz = pz / pz.sum()\n",
    "pzw = beta.multiply(pz, 0).divide(pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_test = test.replace(0, np.nan).transpose().unstack().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_ratings = ratings.replace(0, np.nan).subtract(user_means['mean'], 0).divide(user_offsets, 0).fillna(value=0)\n",
    "user_similarity = get_similiarity_matrix(adj_ratings).fillna(value=0)\n",
    "docs = pd.DataFrame(gamma.T[:6040].values, index = ratings.index)\n",
    "doc_similarity  = get_similiarity_matrix(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.010953331644598"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = user_similarity.dot(adj_ratings)\n",
    "denom = user_similarity.abs().sum().transpose()\n",
    "predictions = predictions.div(denom, axis='index').multiply(user_offsets, 0).add(user_means['mean'], 0).fillna(value=1)\n",
    "get_rmse(predictions, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0070253685672468"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = doc_similarity.dot(adj_ratings)\n",
    "denom = doc_similarity.abs().sum().transpose()\n",
    "predictions = predictions.div(denom, axis='index').multiply(user_offsets, 0).add(user_means['mean'], 0)\n",
    "get_rmse(predictions, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : 0.996940184171\n",
      "10 : 0.985678604479\n",
      "20 : 0.978858026378\n",
      "30 : 1.0384348066\n",
      "50 : 0.977512032462\n",
      "100 : 0.979113652489\n",
      "150 : 0.981677413447\n"
     ]
    }
   ],
   "source": [
    "for k in [5,10,20,30,50, 100, 150]:\n",
    "    simil = adjust_user_similarity_knn(user_similarity, k)\n",
    "    predictions = simil.dot(adj_ratings)\n",
    "    denom = simil.abs().sum().transpose()\n",
    "    predictions = predictions.div(denom, axis='index').multiply(user_offsets, 0).add(user_means['mean'], 0).fillna(value=1)\n",
    "    predictions = predictions.fillna(value=3).replace(np.inf, 3).replace(-np.inf, 3)\n",
    "    print k, \":\", get_rmse(predictions, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : 1.2894545312\n",
      "10 : 1.22384671872\n",
      "20 : 1.1535726669\n",
      "30 : 1.10039275379\n",
      "50 : 1.03333114785\n",
      "100 : 1.00154170175\n",
      "150 : 1.00241251734\n"
     ]
    }
   ],
   "source": [
    "for k in [5,10,20,30,50, 100, 150]:\n",
    "    simil = adjust_user_similarity_knn(doc_similarity, k)\n",
    "    predictions = simil.dot(adj_ratings)\n",
    "    denom = simil.abs().sum().transpose()\n",
    "    predictions = predictions.div(denom, axis='index').multiply(user_offsets, 0).add(user_means['mean'], 0).fillna(value=1)\n",
    "    predictions = predictions.fillna(value=3).replace(np.inf, 3).replace(-np.inf, 3)\n",
    "    print k, \":\", get_rmse(predictions, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : 1.39630091786\n",
      "10 : 1.34089590469\n",
      "20 : 1.25737148269\n",
      "30 : 1.18389470134\n",
      "50 : 1.08058735804\n",
      "100 : 1.01551969801\n",
      "150 : 1.00507971672\n"
     ]
    }
   ],
   "source": [
    "for k in [5,10,20,30,50, 100, 150]:\n",
    "    simil = adjust_user_similarity_knn(doc_similarity, k)\n",
    "    predictions = simil.dot(adj_ratings)\n",
    "    denom = simil.abs().sum().transpose()\n",
    "    predictions = predictions.div(denom, axis='index').multiply(user_offsets, 0).add(user_means['mean'], 0).fillna(value=1)\n",
    "    predictions = predictions.fillna(value=1).replace(np.inf, 1).replace(-np.inf, 1)\n",
    "    print k, \":\", get_rmse(predictions, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim(movie, user, k):\n",
    "    enum = user.multiply(movie).sum()\n",
    "    denom = np.sqrt(user.multiply(user).sum()) * np.sqrt(movie.multiply(movie).sum())\n",
    "    return enum / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.corrcoef(pzw[movies.get_loc(745)], gamma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for id, rating in new_test[1].sort_values().iteritems():\n",
    "    print id, sim(pzw[movies.get_loc(id)], gamma[0], 20).round(2), rating\n",
    "    print id, np.corrcoef(pzw[movies.get_loc(id)].values, gamma[0].values), rating\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pzw[movies.get_loc(745)].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rmse\n",
    "total = 0\n",
    "count = 0\n",
    "bl_total = 0\n",
    "new_test = test.replace(0, np.nan).transpose().unstack().dropna()\n",
    "\n",
    "for user in users:\n",
    "    userId = user\n",
    "    if userId % 500 == 0:\n",
    "        print userId, \n",
    "        \n",
    "    mean = user_means[\"mean\"][userId]\n",
    "    offset = user_offsets[userId]\n",
    "    \n",
    "    for movie in new_test[userId].iteritems():\n",
    "        movieId, rating = movie\n",
    "        movie_mean = item_means[\"mean\"][movieId]\n",
    "        sim = get_sim(userId, movieId, gamma, pzw, movies, topics)\n",
    "\n",
    "        if offset < 0:\n",
    "            pred = (movie_mean + offset - 2*sim*offset).clip(1,5).round(0)\n",
    "        else:\n",
    "            pred = (movie_mean - offset + 2*sim*offset).clip(1,5).round(0)\n",
    "        \n",
    "        error = rating - pred\n",
    "        bl_error = rating - (movie_mean+offset)\n",
    "        bl_total += bl_error * bl_error\n",
    "        total += error * error\n",
    "        count += 1\n",
    "        \n",
    "avg_error = total/count\n",
    "avg_bl_error = bl_total/count\n",
    "print \n",
    "print np.sqrt(avg_error)\n",
    "print np.sqrt(avg_bl_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
